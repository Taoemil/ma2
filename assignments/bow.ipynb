{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI & Machine Learning (KAN-CINTO4003U) - Copenhagen Business School | Spring 2025**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Part I: Bag-of-Words Model\n",
    "\n",
    "Please see the description of the assignment in the README file (section 1) <br>\n",
    "**Guide notebook**: [guides/bow_guide.ipynb](guides/bow_guide.ipynb)\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "<br>\n",
    "\n",
    "* Note that you should report results using a classification report. \n",
    "\n",
    "* Also, remember to include some reflections on your results: Are there any hyperparameters that are particularly important?\n",
    "\n",
    "* You should follow the steps given in the `bow_guide` notebook\n",
    "\n",
    "<br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for the project\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data\n",
    "\n",
    "We can load this data directly from [Hugging Face Datasets](https://huggingface.co/docs/datasets/) - The HuggingFace Hub- into a Pandas DataFrame. Pretty neat!\n",
    "\n",
    "**Note**: This cell will download the dataset and keep it in memory. If you run this cell multiple times, it will download the dataset multiple times.\n",
    "\n",
    "You are welcome to increase the `frac` parameter to load more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 2) (7600, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "\n",
    "train = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"train\"])\n",
    "test = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"test\"])\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1200, 2), (760, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "label_map = {\n",
    "    0: 'World',\n",
    "    1: 'Sports',\n",
    "    2: 'Business',\n",
    "    3: 'Sci/Tech'\n",
    "}\n",
    "\n",
    "def preprocess(df: pd.DataFrame, frac : float = 1e-2, label_map : dict[int, str] = label_map, seed : int = 42) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\" Preprocess the dataset \n",
    "\n",
    "    Operations:\n",
    "    - Map the label to the corresponding category\n",
    "    - Filter out the labels not in the label_map\n",
    "    - Sample a fraction of the dataset (stratified by label)\n",
    "    \"\"\"\n",
    "\n",
    "    return  (\n",
    "        df\n",
    "        .assign(label=lambda x: x['label'].map(label_map))\n",
    "        [lambda df: df['label'].isin(label_map.values())]\n",
    "        .groupby('label')[[\"text\", \"label\"]]\n",
    "        .apply(lambda x: x.sample(frac=frac, random_state=seed))\n",
    "        .reset_index(drop=True)\n",
    "\n",
    "    )\n",
    "\n",
    "train_df = preprocess(train, frac=0.01)\n",
    "test_df = preprocess(test, frac=0.1)\n",
    "\n",
    "# clear up some memory by deleting the original dataframes\n",
    "del train\n",
    "del test\n",
    "\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW shape for training data: (1200, 8490)\n",
      "BoW shape for test data: (760, 8490)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# CountVectorizer with hyperparameters\n",
    "vectorizer = CountVectorizer(max_features=8490, stop_words='english')\n",
    "\n",
    "# Fit the vectorizer on the training data\n",
    "X_train = vectorizer.fit_transform(train_df['text'])\n",
    "X_test = vectorizer.transform(test_df['text'])\n",
    "\n",
    "print(\"BoW shape for training data:\", X_train.shape)\n",
    "print(\"BoW shape for test data:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8460526315789474\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Business       0.80      0.80      0.80       190\n",
      "    Sci/Tech       0.83      0.80      0.81       190\n",
      "      Sports       0.89      0.91      0.90       190\n",
      "       World       0.87      0.88      0.87       190\n",
      "\n",
      "    accuracy                           0.85       760\n",
      "   macro avg       0.85      0.85      0.85       760\n",
      "weighted avg       0.85      0.85      0.85       760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Extract target labels\n",
    "y_train = train_df['label']\n",
    "y_test = test_df['label']\n",
    "\n",
    "# Initialize Logistic Regression classifier \n",
    "clf = LogisticRegression(C=0.1, max_iter=100)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Accuracy: 0.8657894736842106\n",
      "TF-IDF Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Business       0.80      0.84      0.82       190\n",
      "    Sci/Tech       0.87      0.80      0.83       190\n",
      "      Sports       0.91      0.94      0.92       190\n",
      "       World       0.88      0.88      0.88       190\n",
      "\n",
      "    accuracy                           0.87       760\n",
      "   macro avg       0.87      0.87      0.87       760\n",
      "weighted avg       0.87      0.87      0.87       760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=8490, stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['text'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_df['text'])\n",
    "\n",
    "# Train Logistic Regression on the TF-IDF features\n",
    "clf_tfidf = LogisticRegression(C=0.5, max_iter=500)\n",
    "clf_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_tfidf = clf_tfidf.predict(X_test_tfidf)\n",
    "print(\"TF-IDF Accuracy:\", accuracy_score(y_test, y_pred_tfidf))\n",
    "print(\"TF-IDF Classification Report:\\n\", classification_report(y_test, y_pred_tfidf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml25-ma2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
